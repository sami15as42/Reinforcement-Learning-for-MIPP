{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a12dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "\n",
    "from mesa import Model, Agent\n",
    "from mesa.time import RandomActivation\n",
    "from mesa.space import SingleGrid, MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from mesa.visualization.ModularVisualization import ModularServer\n",
    "from mesa.visualization.modules import CanvasGrid, ChartModule, TextElement\n",
    "from mesa.visualization.UserParam import UserSettableParameter\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf_agents\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.agents.categorical_dqn import categorical_dqn_agent\n",
    "from tf_agents.networks import categorical_q_network\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "port = 8522\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683d84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(liste):\n",
    "    return [item for sublist in liste for item in sublist]\n",
    "\n",
    "def preprocessing(X_s):\n",
    "    X = []\n",
    "    for liste in X_s:\n",
    "        X += liste.copy()\n",
    "    return np.array(X)\n",
    "\n",
    "def copie_paths(paths):\n",
    "    X = []\n",
    "    for liste in paths:\n",
    "        X.append(liste.copy())\n",
    "    return X\n",
    "\n",
    "def copy_X_D(X_D):\n",
    "    X = []\n",
    "    for liste in X_D:\n",
    "        X.append(liste.copy())\n",
    "    return np.array(X)\n",
    "\n",
    "def concatenate(x, y):\n",
    "    if len(x)==0:\n",
    "        return y\n",
    "    else:\n",
    "        return np.concatenate((x, y))\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "def distance(a,b):\n",
    "    return np.sqrt((a[0]-b[0])**2 + (a[1]-b[1])**2)\n",
    "        \n",
    "def sigma_matrix(gp_model, X_v):\n",
    "    return gp_model.kern.K(X_v, X_v)\n",
    "    \n",
    "def sigma_prime_matrix(gp_model, X_v, X_s):\n",
    "    kernel = gp_model.rbf\n",
    "    variance_n = float(gp_model.Gaussian_noise.variance)\n",
    "    a = kernel.K(X_v, X_v)\n",
    "    b = kernel.K(X_v, X_s)\n",
    "    c = kernel.K(X_s, X_s)\n",
    "    d = variance_n*np.eye(len(X_s))\n",
    "    e = kernel.K(X_s, X_v)\n",
    "    f = np.linalg.inv(c + d)\n",
    "    g = np.dot(b, f)\n",
    "    h = np.dot(g, e)\n",
    "    return a - h\n",
    "\n",
    "def reward_function(gp_model, X_v, X_s_old, X_s_new):\n",
    "    if len(X_s_old)==0:\n",
    "        sigma_prime_old = sigma_matrix(gp_model, X_v)\n",
    "    else:\n",
    "        sigma_prime_old = sigma_prime_matrix(gp_model, X_v, X_s_old)\n",
    "    if len(X_s_new)==0:\n",
    "        sigma_prime_new = sigma_matrix(gp_model, X_v)\n",
    "    else:\n",
    "        sigma_prime_new = sigma_prime_matrix(gp_model, X_v, X_s_new)\n",
    "    return 0.5 * (np.log(np.linalg.det(sigma_prime_old)) - np.log(np.linalg.det(sigma_prime_new)))\n",
    "\n",
    "def credit_assignment(env, reward, dones):\n",
    "    if env.nb_agents==1:\n",
    "        return np.array([reward])\n",
    "    rewards = np.zeros(env.nb_agents)\n",
    "    if reward==0:\n",
    "        return rewards\n",
    "    X_s = preprocessing(env.X_s)\n",
    "    H = np.log(np.linalg.det(sigma_prime_matrix(env.gp_model, env.X_v, X_s)))\n",
    "    for i in range(env.nb_agents):\n",
    "        if not dones[i]:\n",
    "            X_s_i = env.X_s.copy()\n",
    "            del X_s_i[i]\n",
    "            X_s_i = preprocessing(X_s_i)\n",
    "            if len(X_s_i)==0:\n",
    "                rewards[i] = 0.5 * (np.log(np.linalg.det(sigma_matrix(env.gp_model, env.X_v))) - H)\n",
    "            else:\n",
    "                rewards[i] = 0.5 * (np.log(np.linalg.det(sigma_prime_matrix(env.gp_model, env.X_v, X_s_i))) - H)\n",
    "    somme = np.sum(rewards)\n",
    "    if somme==0:\n",
    "        return rewards\n",
    "    return rewards*(reward/(np.sum(rewards)))\n",
    "\n",
    "def construct_graph(graph_dim, graph_unity):\n",
    "    x = graph_dim[0]\n",
    "    y = graph_dim[1]\n",
    "    i, j = 0.0, 0.0\n",
    "    graph = nx.Graph()\n",
    "    for k in range(x*y):\n",
    "        graph.add_node(k, coord=[i, j])\n",
    "        i += graph_unity\n",
    "        if i==x*graph_unity:\n",
    "            i = 0.0\n",
    "            j += graph_unity\n",
    "    for k in range(x*y):\n",
    "        if (k+1)%x!=0:\n",
    "            graph.add_edge(k, k+1)\n",
    "        if k<x*y-x:\n",
    "            graph.add_edge(k, k+x)\n",
    "    return graph\n",
    "            \n",
    "def show_graph(graph):\n",
    "    nx.draw(graph, with_labels=True, font_weight='bold')\n",
    "\n",
    "def remove_nodes_from_graph(graph, liste):\n",
    "    graph.remove_nodes_from(liste)\n",
    "    return graph\n",
    "\n",
    "def incertitude_initiale(sigma, graph):\n",
    "    return 0.5 * np.log(np.linalg.det(sigma)) + (graph.number_of_nodes()/2) * (1 + np.log(2*np.pi))\n",
    "\n",
    "def coord_to_id(coord, graph_dim):\n",
    "    return graph_dim[0] * int(coord[1]) + int(coord[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc691978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pilot_data(nb_agents, exploration_steps, graph, graph_dim, means, variance, lengthscale, memory_window, gamma):\n",
    "    X_D = np.array([graph.nodes[i][\"coord\"] for i in range(graph.number_of_nodes())])\n",
    "    simulation_kernel = GPy.kern.RBF(input_dim = 2, variance=variance, lengthscale=lengthscale)\n",
    "    cov = simulation_kernel.K(X_D)\n",
    "    X, Y = [], []\n",
    "    for _ in range(exploration_steps):\n",
    "        Y_D = np.random.multivariate_normal(np.array(means), cov, 1)[0]\n",
    "        Y_D = np.reshape(Y_D, (len(Y_D),1))\n",
    "        Y_D[Y_D<0] = 0.1\n",
    "        sparse_nodes = random.sample(range(0, graph.number_of_nodes()), nb_agents)\n",
    "        sorted_nodes = sorted(sparse_nodes)\n",
    "        if sorted_nodes[0]==0:\n",
    "            for i in range(1,len(sorted_nodes)):\n",
    "                if sorted_nodes[i]!=sorted_nodes[i-1]:\n",
    "                    l = covariances[sorted_nodes[i]-1]\n",
    "                    l[0], l[1], l[2], l[3] = weighted_covariance(l[0], l[1], l[2], l[3], Y_D[0], Y_D[sorted_nodes[i]], memory_window, gamma)\n",
    "        X.append(X_D[sparse_nodes])\n",
    "        Y.append(Y_D[sparse_nodes])\n",
    "    return incertitude_initiale(cov, graph), np.array(X), np.array(Y)\n",
    "\n",
    "def hyperparameters_estimator(X, Y, gp_model, graph, graph_dim, memory_window, gamma):\n",
    "    for i in range(len(X)):\n",
    "        l = variances[coord_to_id(X[i], graph_dim)]\n",
    "        l[0], l[1], l[2] = weighted_variance(l[0], l[1], l[2], Y[i][0], memory_window, gamma)\n",
    "    cumul_var = 0\n",
    "    coeffs = 0\n",
    "    for ele in variances:\n",
    "        coeffs += ele[2]\n",
    "        cumul_var += float(ele[0])*ele[2]\n",
    "    variance = cumul_var/coeffs\n",
    "    ###########################################\n",
    "    X_v = np.array([graph.nodes[i][\"coord\"] for i in range(graph.number_of_nodes())])\n",
    "    moyenne = np.reshape(gp_model.predict(X_v)[0], (graph.number_of_nodes(),))\n",
    "    ###########################################\n",
    "    lengthscale, cpt = 0, 0\n",
    "    for i in range(len(covariances)):\n",
    "        if covariances[i][0]>1:\n",
    "            covariance = covariances[i][1] - covariances[i][2]*covariances[i][3]\n",
    "            if 0<covariance<variance:\n",
    "                cpt += covariances[i][0]\n",
    "                lengthscale += find_lengthscale(X_v[0], X_v[i+1], covariance, variance) * covariances[i][0]\n",
    "    if cpt!=0:\n",
    "        lengthscale /= cpt\n",
    "    else:\n",
    "        lengthscale = 0\n",
    "    return moyenne, variance, lengthscale\n",
    "\n",
    "def find_lengthscale(x1, x2, y, var):\n",
    "    return distance(x1, x2) * np.sqrt(-0.5/np.log(y/var))\n",
    "\n",
    "def weighted_covariance(n, moy_prod, moy_x, moy_y, x_new, y_new, memory_capacity, gamma):\n",
    "    if n>memory_capacity:\n",
    "        return n + 1, gamma * moy_prod + (1-gamma) * x_new * y_new, gamma * moy_x + (1-gamma) * x_new, gamma * moy_y + (1-gamma) * y_new\n",
    "    return n + 1, (n * moy_prod + x_new * y_new)/(n + 1), (n * moy_x + x_new)/(n + 1), (n * moy_y + y_new)/(n + 1)\n",
    "\n",
    "def weighted_variance(var, moy, n, x_new, memory_capacity, gamma):\n",
    "    if n>memory_capacity:\n",
    "        a = gamma*(var+(moy**2)) + (1-gamma)*(x_new**2)\n",
    "        moy = gamma * moy + (1-gamma) * x_new\n",
    "    else:\n",
    "        a = (n*(var+(moy**2)) + (x_new**2))/(n+1)\n",
    "        moy = (n*moy+x_new)/(n+1)\n",
    "    return a-moy**2, moy, n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e15610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  6.630500994933553\n",
      "Lengthscale:  [1.33462695]\n",
      "Carte:  [61.42182314 30.70830029 18.24825012 14.60216164 11.17113024 32.32974597\n",
      " 23.91409301 24.45371176 18.73139786 10.29112404 18.15012332 21.01698463\n",
      " 24.29303785 17.92047225 10.56134434 13.03002171 15.47067502 18.72326228\n",
      " 18.00522531 16.03398151  9.67046301 11.76729391 15.56039682 15.7214703\n",
      " 11.54153804]\n",
      "Incertitude initiale :  81.94223693030234\n"
     ]
    }
   ],
   "source": [
    "graph_dim = (5, 5)\n",
    "graph_unity = 1\n",
    "graph = construct_graph(graph_dim, graph_unity)\n",
    "X_v = np.array([graph.nodes[i][\"coord\"] for i in range(graph.number_of_nodes())])\n",
    "means = [60, 30, 20, 15, 10, 30, 27.5, 25, 17.5, 11.25, 20, 25, 22.5, 20, 12.5, 15, 17.5, 20, 17.5, 15, 10, 11.25, 12.5, 15, 12.5]\n",
    "nb_agents = 3\n",
    "exploration_steps = 25\n",
    "variance_lengthscale = [10, 2]\n",
    "memory_window = 1000\n",
    "gamma = 0.997\n",
    "\n",
    "variances = [[0, 0, 0] for _ in range(graph.number_of_nodes())]\n",
    "covariances = [[0, 0, 0, 0] for _ in range(graph.number_of_nodes()-1)]\n",
    "\n",
    "incertitude, x, y = collect_pilot_data(nb_agents, exploration_steps, graph, graph_dim, means, variance_lengthscale[0], variance_lengthscale[1], memory_window, gamma)\n",
    "\n",
    "x = np.reshape(x, (nb_agents*exploration_steps,2))\n",
    "y = np.reshape(y, (nb_agents*exploration_steps,1))\n",
    "\n",
    "gp_model = GPy.models.GPRegression(x, y, GPy.kern.RBF(2))\n",
    "gp_model.optimize(messages=False)\n",
    "\n",
    "moyenne, var, l = hyperparameters_estimator(x, y, gp_model, graph, graph_dim, memory_window, gamma)\n",
    "print(\"Variance: \", var)\n",
    "print(\"Lengthscale: \", l)\n",
    "print(\"Carte: \", moyenne)\n",
    "print(\"Incertitude initiale : \", incertitude_initiale(sigma_matrix(gp_model, X_v), graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567a147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc6e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef738cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b643543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_gp_model(gp_model, x, y, graph, graph_dim, memory_window, gamma, display_gp_model=False):\n",
    "    moy, variance, lengthscale = hyperparameters_estimator(x, y, gp_model, graph, graph_dim, memory_window, gamma)\n",
    "    X = np.concatenate((gp_model.X, x))[-1000:]\n",
    "    Y = np.concatenate((gp_model.Y, y))[-1000:]\n",
    "    gp_model.set_XY(X, Y)\n",
    "    gp_model.optimize(messages=False)\n",
    "    if display_gp_model:\n",
    "        display(gp_model)\n",
    "    return gp_model, moy, variance, lengthscale\n",
    "\n",
    "def take_measurements(nodes, means, X_v, memory_window, gamma):\n",
    "    simulation_kernel = GPy.kern.RBF(input_dim = 2, variance=variance_lengthscale[0], lengthscale=variance_lengthscale[1])\n",
    "    cov = simulation_kernel.K(X_v)\n",
    "    Y_v = np.random.multivariate_normal(np.array(means), cov, 1)[0]\n",
    "    Y_v = np.reshape(Y_v, (len(Y_v),1))\n",
    "    Y_v[Y_v<0] = 0.1\n",
    "    sorted_nodes = sorted(nodes)\n",
    "    if sorted_nodes[0]==0:\n",
    "        for i in range(1,len(sorted_nodes)):\n",
    "            if sorted_nodes[i]!=sorted_nodes[i-1]:\n",
    "                l = covariances[sorted_nodes[i]-1]\n",
    "                l[0], l[1], l[2], l[3] = weighted_covariance(l[0], l[1], l[2], l[3], Y_v[0], Y_v[sorted_nodes[i]], memory_window, gamma)\n",
    "    return X_v[nodes], Y_v[nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6baa6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pfeEnv(py_environment.PyEnvironment):\n",
    "\n",
    "    def __init__(self, graph, gp_model, nb_agents, budgets, graph_unity, graph_dim, initial_positions, variance_0, lengthscale_0, memory_window, gamma, train_env=True):\n",
    "        self.nb_agents = nb_agents\n",
    "        self.graph = graph\n",
    "        self.graph_unity = graph_unity\n",
    "        self.graph_dim = graph_dim\n",
    "        self.initial_budgets = budgets/self.graph_unity\n",
    "        self.budgets = self.initial_budgets.copy()\n",
    "        if initial_positions!=None:\n",
    "            self.initial_positions = copie_paths(initial_positions)\n",
    "            self.paths = copie_paths(initial_positions)\n",
    "        else:\n",
    "            self.initial_positions = None\n",
    "            self.paths = [[random.randint(0, self.graph.number_of_nodes()-1)] for i in range(self.nb_agents)]\n",
    "        self.neighbors = [sorted(list(self.graph.neighbors(self.current_node(i)))) for i in range(self.nb_agents)]\n",
    "        self.formater()\n",
    "        self.X_v = np.array([self.graph.nodes[i][\"coord\"] for i in range(self.graph.number_of_nodes())])\n",
    "        self.gp_model = gp_model\n",
    "        self.X_s = [[] for i in range(self.nb_agents)]\n",
    "        self.dones = [False for i in range(self.nb_agents)]\n",
    "        self.cpt_done = 0\n",
    "        self._action_spec = array_spec.BoundedArraySpec(shape=(), dtype=np.int32, minimum=0, maximum=3, name=\"action\")\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(shape=(self.nb_agents*2,), dtype=np.float32, minimum=np.zeros((self.nb_agents*2,)), name=\"observation\")\n",
    "        self._state = flatten([self.graph.nodes[self.current_node(i)][\"coord\"] for i in range(self.nb_agents)])\n",
    "        self._episode_ended = False\n",
    "        #################################\n",
    "        self.cpt_update_gp_model = 0\n",
    "        self.memory_window, self.gamma = memory_window, gamma\n",
    "        self.x, self.y = np.array([]), np.array([])\n",
    "        self.liste_variances, self.liste_lengthscales = [variance_0], [lengthscale_0]\n",
    "        self.train_env = train_env\n",
    "        self.agents_in_collision = []\n",
    "        \n",
    "    def current_node(self, id_agent):\n",
    "        return self.paths[id_agent][-1]\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "    \n",
    "    def current_node_coord(self, id_agent):\n",
    "        coord = self.graph.nodes[self.current_node(id_agent)][\"coord\"]\n",
    "        return (int(coord[0]), int(coord[1]))\n",
    "    \n",
    "    def formater(self):\n",
    "        for i in range(len(self.neighbors)):\n",
    "            liste = self.neighbors[i]\n",
    "            node = self.current_node(i)\n",
    "            try:\n",
    "                if liste[0]>=node-1:\n",
    "                    liste.insert(0,-1)\n",
    "                if liste[1]!=node-1:\n",
    "                    liste.insert(1,-1)\n",
    "                if liste[2]!=node+1:\n",
    "                    liste.insert(2,-1)\n",
    "            except:\n",
    "                pass\n",
    "            for _ in range(4-len(liste)):\n",
    "                liste.append(-1)\n",
    "\n",
    "    def _reset(self):\n",
    "        if self.initial_positions!=None:\n",
    "            self.paths = copie_paths(self.initial_positions)\n",
    "        else:\n",
    "            self.paths = [[random.randint(0, self.graph.number_of_nodes()-1)] for i in range(self.nb_agents)]\n",
    "        self._state = flatten([self.graph.nodes[self.current_node(i)][\"coord\"] for i in range(self.nb_agents)])\n",
    "        self.neighbors = [sorted(list(self.graph.neighbors(self.current_node(i)))) for i in range(self.nb_agents)] \n",
    "        self.formater()\n",
    "        self.budgets = self.initial_budgets.copy()\n",
    "        self.X_s = [[] for i in range(self.nb_agents)]\n",
    "        self.dones = [False for i in range(self.nb_agents)]\n",
    "        self.cpt_done = 0\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array(self._state, dtype=np.float32))\n",
    "        \n",
    "    def _step(self, abstract_actions):\n",
    "        if self._episode_ended:\n",
    "            return self.reset()\n",
    "        actions = []\n",
    "        for i in range(self.nb_agents):\n",
    "            actions.append(self.neighbors[i][abstract_actions[i]])\n",
    "        X_s_old = preprocessing(self.X_s)\n",
    "        for i in range(self.nb_agents):\n",
    "            if not self.dones[i]:\n",
    "                if actions[i]!=-1:\n",
    "                    self.X_s[i].append([graph.nodes[actions[i]][\"coord\"][0], graph.nodes[actions[i]][\"coord\"][1]])\n",
    "                    self.budgets[i] -= 1\n",
    "                else:\n",
    "                    actions[i] = self.current_node(i)\n",
    "                    self.budgets[i] -= 0.3\n",
    "                if self.budgets[i]<1:\n",
    "                    self.dones[i] = True\n",
    "                    self.cpt_done += 1\n",
    "                self.paths[i].append(actions[i])\n",
    "                coord = self.graph.nodes[self.current_node(i)][\"coord\"]\n",
    "                self._state[2*i] = coord[0]\n",
    "                self._state[2*i+1] = coord[1]\n",
    "        \n",
    "        if self.train_env:\n",
    "            positions, mesures = take_measurements(actions, means, self.X_v, self.memory_window, self.gamma)\n",
    "            self.x = concatenate(self.x, positions)\n",
    "            self.y = concatenate(self.y, mesures)\n",
    "            self.cpt_update_gp_model = (self.cpt_update_gp_model + 1)%100\n",
    "            if self.cpt_update_gp_model==0:\n",
    "                self.gp_model, m, var, l = update_gp_model(self.gp_model, self.x, self.y, self.graph, self.graph_dim, self.memory_window, self.gamma)\n",
    "                self.liste_variances.append(var)\n",
    "                self.liste_lengthscales.append(l)\n",
    "                self.moy = m\n",
    "                self.x, self.y = np.array([]), np.array([])\n",
    "        \n",
    "        self.neighbors = [sorted(list(self.graph.neighbors(self.current_node(i)))) for i in range(self.nb_agents)]\n",
    "        self.formater()\n",
    "        reward = reward_function(self.gp_model, self.X_v, X_s_old, preprocessing(self.X_s))\n",
    "        if self.cpt_done==self.nb_agents:\n",
    "            self._episode_ended = True\n",
    "            return ts.termination(np.array(self._state, dtype=np.float32), reward)\n",
    "        return ts.transition(np.array(self._state, dtype=np.float32), reward=reward, discount=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5875617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10000\n",
    "fc_layer_params = (128,64,)\n",
    "replay_buffer_capacity = 300000\n",
    "batch_size = 128\n",
    "learning_rate = 1e-5\n",
    "\n",
    "num_atoms = 51\n",
    "min_q_value = -20\n",
    "max_q_value = 20\n",
    "n_step_update = 3\n",
    "gamma = 0.99\n",
    "\n",
    "num_eval_episodes = 10\n",
    "log_eval_interval = 1000\n",
    "\n",
    "max_episode_length = 25\n",
    "budgets = 25 * np.ones(nb_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "453fc622",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_positions = None #[[random.randint(0, graph.number_of_nodes()-1)] for i in range(nb_agents)]\n",
    "train_py_env = wrappers.TimeLimit(pfeEnv(graph, gp_model, nb_agents, budgets, graph_unity, graph_dim, initial_positions, var, l, memory_window, gamma, train_env=True), duration=max_episode_length)\n",
    "eval_py_env = wrappers.TimeLimit(pfeEnv(graph, gp_model, nb_agents, budgets, graph_unity, graph_dim, initial_positions, var, l, memory_window, gamma, train_env=False), duration=max_episode_length)\n",
    "mesa_py_env = wrappers.TimeLimit(pfeEnv(graph, gp_model, nb_agents, budgets, graph_unity, graph_dim, initial_positions, var, l, memory_window, gamma, train_env=True), duration=max_episode_length)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "mesa_env = tf_py_environment.TFPyEnvironment(mesa_py_env)\n",
    "\n",
    "agents_tf = []\n",
    "eval_policies = []\n",
    "collect_policies = []\n",
    "policies_checkpointers = []\n",
    "\n",
    "for i in range(nb_agents):\n",
    "    categorical_q_net = categorical_q_network.CategoricalQNetwork(\n",
    "        train_env.observation_spec(),\n",
    "        train_env.action_spec(),\n",
    "        num_atoms=num_atoms,\n",
    "        fc_layer_params=fc_layer_params)\n",
    "        \n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "    train_step_counter = tf.compat.v2.Variable(0)\n",
    "\n",
    "    agents_tf.append(categorical_dqn_agent.CategoricalDqnAgent(\n",
    "        train_env.time_step_spec(),\n",
    "        train_env.action_spec(),\n",
    "        categorical_q_network=categorical_q_net,\n",
    "        optimizer=optimizer,\n",
    "        min_q_value=min_q_value,\n",
    "        max_q_value=max_q_value,\n",
    "        n_step_update=n_step_update,\n",
    "        target_update_period=5,\n",
    "        target_update_tau=0.05,\n",
    "        td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "        gamma=gamma,\n",
    "        train_step_counter=train_step_counter))\n",
    "\n",
    "    agents_tf[-1].initialize()\n",
    "\n",
    "    eval_policies.append(agents_tf[-1].policy)\n",
    "    collect_policies.append(agents_tf[-1].collect_policy)\n",
    "    \n",
    "    policies_checkpointers.append(common.Checkpointer(ckpt_dir='Meza_Inference_Politique_'+str(i), policy=eval_policies[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "562a871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policies, num_episodes=10):\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "        while not time_step.is_last():\n",
    "            actions = []\n",
    "            for i in range(nb_agents):\n",
    "                actions.append(policies[i].action(time_step).action.numpy()[0])\n",
    "            actions = tf.convert_to_tensor([actions])\n",
    "            time_step = environment.step(actions)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]\n",
    "\n",
    "def collect_step(environment, environment_py, policies):\n",
    "    time_step = environment.current_time_step()\n",
    "    actions = []\n",
    "    actions_step = []\n",
    "    dones = environment_py.dones.copy()\n",
    "    for i in range(nb_agents):\n",
    "        actions_step.append(policies[i].action(time_step))\n",
    "        actions.append(actions_step[-1].action.numpy()[0])\n",
    "    actions = tf.convert_to_tensor([actions])\n",
    "    next_time_step = environment.step(actions)\n",
    "    rewards = credit_assignment(environment_py, next_time_step.reward.numpy()[0], dones)\n",
    "    for i in range(nb_agents):\n",
    "        if not dones[i]:\n",
    "            nts = next_time_step._replace(reward=tf.convert_to_tensor([rewards[i]], dtype=np.float32))\n",
    "            traj = trajectory.from_transition(time_step, actions_step[i], nts)\n",
    "            replay_buffers[i].add_batch(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ea3fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffers = []\n",
    "for i in range(nb_agents):\n",
    "    replay_buffers.append(tf_agents.replay_buffers.TFUniformReplayBuffer(\n",
    "        data_spec = agents_tf[i].collect_data_spec,\n",
    "        batch_size = train_env.batch_size,\n",
    "        max_length = replay_buffer_capacity))\n",
    "\n",
    "iterators = []\n",
    "for i in range(nb_agents):\n",
    "    dataset = replay_buffers[i].as_dataset(\n",
    "        num_parallel_calls=3,\n",
    "        sample_batch_size=batch_size,\n",
    "        num_steps=2).prefetch(3)\n",
    "\n",
    "    iterators.append(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f61a627d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.14046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 21.99it/s]\n",
      "  0%|                                                                                        | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hm_as\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hm_as\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      " 10%|███████▋                                                                     | 1003/10000 [01:11<55:36,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1000: Average Return = 12.150976181030273\n",
      "Variance :  10.446393067860985\n",
      "Lengthscale :  [2.3804683]\n",
      "MSE de la moyenne :  1.6691729808851332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▍                                                             | 2003/10000 [02:26<59:52,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 2000: Average Return = 13.731318473815918\n",
      "Variance :  9.967941958608003\n",
      "Lengthscale :  [2.33152703]\n",
      "MSE de la moyenne :  32.860536043521826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████▏                                                     | 3004/10000 [03:39<41:36,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 3000: Average Return = 15.836660385131836\n",
      "Variance :  10.352956289717962\n",
      "Lengthscale :  [2.37870005]\n",
      "MSE de la moyenne :  13.583119124943288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▊                                              | 4004/10000 [04:52<36:06,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 4000: Average Return = 37.2549934387207\n",
      "Variance :  10.057641285712606\n",
      "Lengthscale :  [2.43289531]\n",
      "MSE de la moyenne :  4.958543506446828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▌                                      | 5002/10000 [06:09<42:07,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5000: Average Return = 28.419185638427734\n",
      "Variance :  9.95204766910792\n",
      "Lengthscale :  [2.52215314]\n",
      "MSE de la moyenne :  0.31946700192522093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████▏                              | 6003/10000 [07:25<25:15,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6000: Average Return = 30.206005096435547\n",
      "Variance :  9.704917536829907\n",
      "Lengthscale :  [2.14139052]\n",
      "MSE de la moyenne :  0.4028039671780938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▉                       | 7002/10000 [08:39<23:02,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 7000: Average Return = 27.8193302154541\n",
      "Variance :  10.028797851924185\n",
      "Lengthscale :  [2.18522876]\n",
      "MSE de la moyenne :  1.2001778135870602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████▌               | 8003/10000 [09:49<11:36,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 8000: Average Return = 29.488811492919922\n",
      "Variance :  10.01004005777529\n",
      "Lengthscale :  [2.03626913]\n",
      "MSE de la moyenne :  0.39873675332369546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████▎       | 9001/10000 [11:04<08:30,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 9000: Average Return = 32.085147857666016\n",
      "Variance :  9.917304423544104\n",
      "Lengthscale :  [2.03539823]\n",
      "MSE de la moyenne :  0.9479413374128446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [12:16<00:00, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 10000: Average Return = 32.451839447021484\n",
      "Variance :  9.954908702948185\n",
      "Lengthscale :  [2.06062099]\n",
      "MSE de la moyenne :  1.019219043201156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(compute_avg_return(eval_env, eval_policies, num_eval_episodes))\n",
    "\n",
    "steps = []\n",
    "avg = []\n",
    "err = []\n",
    "\n",
    "for i in range(nb_agents):\n",
    "    agents_tf[i].train = common.function(agents_tf[i].train)\n",
    "    agents_tf[i].train_step_counter.assign(0)\n",
    "\n",
    "for _ in tqdm(range(500)):\n",
    "    collect_step(train_env, train_py_env, collect_policies)\n",
    "    \n",
    "for step in tqdm(range(1, num_iterations+1)):\n",
    "    for _ in range(1):\n",
    "        collect_step(train_env, train_py_env, collect_policies)\n",
    "    \n",
    "    for i in range(nb_agents):\n",
    "        experience, _ = next(iterators[i])\n",
    "        agents_tf[i].train(experience=experience)\n",
    "\n",
    "    if step%log_eval_interval==0:\n",
    "        avg_return = compute_avg_return(eval_env, eval_policies, num_eval_episodes)\n",
    "        steps.append(step)\n",
    "        avg.append(avg_return)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        print(\"Variance : \", train_py_env.liste_variances[-1])\n",
    "        print(\"Lengthscale : \", train_py_env.liste_lengthscales[-1])\n",
    "        err.append(np.mean((train_py_env.moy-means)**2))\n",
    "        print(\"MSE de la moyenne : \", err[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92ba0053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25.944427, 19.68109974825392, 32.20775523221483)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x206507c2130>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(mean_confidence_interval(avg, confidence=0.95))\n",
    "plt.plot(steps, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb63bf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 11, 16, 21, 16, 11, 6, 7, 2, 1, 0, 5, 10, 11, 6, 7, 2, 3, 2, 1, 6, 1, 0, 5, 10, 11], [8, 13, 18, 17, 16, 15, 16, 11, 6, 11, 6, 11, 16, 11, 10, 5, 6, 1, 6, 1, 6, 11, 6, 11, 16, 11], [7, 6, 11, 16, 21, 16, 17, 22, 21, 20, 20, 20, 20, 21, 22, 23, 24, 23, 22, 21, 20, 20, 20, 20, 20, 21]]\n",
      "32.054867\n",
      "##################################\n",
      "Moyenne :  32.054867\n"
     ]
    }
   ],
   "source": [
    "total_return = 0.0\n",
    "episodes = 1\n",
    "for _ in range(episodes):\n",
    "    time_step = eval_env.reset()\n",
    "    episode_return = 0.0\n",
    "    while not time_step.is_last():\n",
    "        actions = []\n",
    "        for i in range(nb_agents):\n",
    "            actions.append(eval_policies[i].action(time_step).action.numpy()[0])\n",
    "        actions = tf.convert_to_tensor([actions])\n",
    "        time_step = eval_env.step(actions)\n",
    "        episode_return += time_step.reward\n",
    "    print(eval_py_env.paths)\n",
    "    print(episode_return.numpy()[0])\n",
    "    print(\"##################################\")\n",
    "    total_return += episode_return\n",
    "avg_return = total_return / episodes\n",
    "print(\"Moyenne : \", avg_return.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02520630",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_agents):\n",
    "    policies_checkpointers[i].save(global_step=agents_tf[i].train_step_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc338723",
   "metadata": {},
   "source": [
    "## Partie Visualisation Mesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3dfe0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizAgent(Agent):\n",
    "    def __init__(self, id_agent, pos, model, agent_type):\n",
    "        super().__init__(id_agent, model)\n",
    "        self.pos = pos\n",
    "        self.type = agent_type\n",
    "\n",
    "    def step(self):\n",
    "        self.model.grid.remove_agent(self)\n",
    "        self.pos = mesa_py_env.current_node_coord(self.unique_id)\n",
    "        self.model.grid.place_agent(self, self.pos)\n",
    "\n",
    "class VizModel(Model):\n",
    "    def __init__(self, width, height, nb_agents, max_episode_length):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.nb_agents = nb_agents\n",
    "        self.max_episode_length = max_episode_length\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.grid = MultiGrid(width, height, torus=True)\n",
    "        self.reward = 0\n",
    "        episode_reward[0] = 0\n",
    "        self.time_step = mesa_env.reset()\n",
    "        \n",
    "        self.datacollector = DataCollector({\"Rewards\": \"reward\"},)\n",
    "        \n",
    "        for i in range(self.nb_agents):\n",
    "            coord = mesa_py_env.current_node_coord(i)\n",
    "            agent = VizAgent(i, coord, self, 0)\n",
    "            self.grid.place_agent(agent, coord)\n",
    "            self.schedule.add(agent)\n",
    "\n",
    "        self.running = True\n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "    def step(self):\n",
    "        if not self.time_step.is_last():\n",
    "            actions = []\n",
    "            for i in range(nb_agents):\n",
    "                actions.append(eval_policies[i].action(self.time_step).action.numpy()[0])\n",
    "            actions = tf.convert_to_tensor([actions])\n",
    "            self.time_step = mesa_env.step(actions)\n",
    "            self.reward += self.time_step.reward.numpy()[0]\n",
    "            episode_reward[0] = self.reward\n",
    "            self.datacollector.collect(self)\n",
    "            self.schedule.step()\n",
    "        else:\n",
    "            rewards.append(self.reward)\n",
    "            self.running = False\n",
    "            \n",
    "class MeanRewardElement(TextElement):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def render(self, model):\n",
    "        try:\n",
    "            return \"Mean Reward: \" + str(round(sum(rewards)/len(rewards), 2))\n",
    "        except:\n",
    "            return \"Mean Reward: 0\"\n",
    "        \n",
    "class EpisodeRewardElement(TextElement):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def render(self, model):\n",
    "        return \"Episode Reward: \" + str(round(episode_reward[0], 2))\n",
    "\n",
    "def agent_draw(agent):\n",
    "    if agent is None:\n",
    "        return\n",
    "    portrayal = {\"Shape\": \"circle\", \"r\": 0.5, \"Filled\": \"true\", \"Layer\": 0, \"Agent\": agent.unique_id}\n",
    "    portrayal[\"Color\"] = list_colors[agent.unique_id]\n",
    "    portrayal[\"stroke_color\"] = \"#000000\"\n",
    "    return portrayal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5736834f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface starting at http://127.0.0.1:8560\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3768/2871458167.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mport\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mesa\\visualization\\ModularVisualization.py\u001b[0m in \u001b[0;36mlaunch\u001b[1;34m(self, port, open_browser)\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[0mwebbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mtornado\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoreload\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mtornado\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mioloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIOLoop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_logging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masyncio_loop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masyncio_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_loop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;34m\"\"\"Run until stop() is called.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_coroutine_origin_tracking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_debug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ident\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This event loop is already running'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Socket opened!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tornado.access:404 GET /favicon.ico (127.0.0.1) 0.00ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\":\"reset\"}\n",
      "{\"type\":\"get_step\",\"step\":1}\n",
      "{\"type\":\"get_step\",\"step\":2}\n",
      "{\"type\":\"get_step\",\"step\":3}\n",
      "{\"type\":\"get_step\",\"step\":4}\n",
      "{\"type\":\"get_step\",\"step\":5}\n",
      "{\"type\":\"get_step\",\"step\":6}\n",
      "{\"type\":\"get_step\",\"step\":7}\n",
      "{\"type\":\"get_step\",\"step\":8}\n",
      "{\"type\":\"get_step\",\"step\":9}\n",
      "{\"type\":\"get_step\",\"step\":10}\n",
      "{\"type\":\"get_step\",\"step\":11}\n",
      "{\"type\":\"get_step\",\"step\":12}\n",
      "{\"type\":\"get_step\",\"step\":13}\n",
      "{\"type\":\"get_step\",\"step\":14}\n",
      "{\"type\":\"get_step\",\"step\":15}\n",
      "{\"type\":\"get_step\",\"step\":16}\n",
      "{\"type\":\"get_step\",\"step\":17}\n",
      "{\"type\":\"get_step\",\"step\":18}\n",
      "{\"type\":\"get_step\",\"step\":19}\n",
      "{\"type\":\"get_step\",\"step\":20}\n",
      "{\"type\":\"get_step\",\"step\":21}\n",
      "{\"type\":\"get_step\",\"step\":22}\n",
      "{\"type\":\"get_step\",\"step\":23}\n",
      "{\"type\":\"get_step\",\"step\":24}\n",
      "{\"type\":\"get_step\",\"step\":25}\n",
      "{\"type\":\"get_step\",\"step\":26}\n",
      "{\"type\":\"get_step\",\"step\":27}\n",
      "{\"type\":\"reset\"}\n",
      "{\"type\":\"get_step\",\"step\":1}\n",
      "{\"type\":\"get_step\",\"step\":2}\n",
      "{\"type\":\"get_step\",\"step\":3}\n",
      "{\"type\":\"get_step\",\"step\":4}\n",
      "{\"type\":\"get_step\",\"step\":5}\n",
      "{\"type\":\"get_step\",\"step\":6}\n",
      "{\"type\":\"get_step\",\"step\":7}\n",
      "{\"type\":\"get_step\",\"step\":8}\n",
      "{\"type\":\"get_step\",\"step\":9}\n",
      "{\"type\":\"get_step\",\"step\":10}\n",
      "{\"type\":\"get_step\",\"step\":11}\n",
      "{\"type\":\"get_step\",\"step\":12}\n",
      "{\"type\":\"get_step\",\"step\":13}\n",
      "{\"type\":\"get_step\",\"step\":14}\n",
      "{\"type\":\"get_step\",\"step\":15}\n",
      "{\"type\":\"get_step\",\"step\":16}\n",
      "{\"type\":\"get_step\",\"step\":17}\n",
      "{\"type\":\"get_step\",\"step\":18}\n",
      "{\"type\":\"get_step\",\"step\":19}\n",
      "{\"type\":\"get_step\",\"step\":20}\n",
      "{\"type\":\"get_step\",\"step\":21}\n",
      "{\"type\":\"get_step\",\"step\":22}\n",
      "{\"type\":\"get_step\",\"step\":23}\n",
      "{\"type\":\"get_step\",\"step\":24}\n",
      "{\"type\":\"get_step\",\"step\":25}\n",
      "{\"type\":\"get_step\",\"step\":26}\n",
      "{\"type\":\"get_step\",\"step\":27}\n",
      "{\"type\":\"reset\"}\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "episode_reward = [0]\n",
    "list_colors = [\"#FF3333\", \"#FFE333\", \"#56FF33\", \"#33FFF7\", \"#3357FF\", \"#C833FF\", \"#FF33AB\"]\n",
    "\n",
    "model_params = {\n",
    "    \"height\": graph_dim[0],\n",
    "    \"width\": graph_dim[1],\n",
    "    \"nb_agents\": nb_agents,\n",
    "    \"max_episode_length\": max_episode_length,\n",
    "}\n",
    "\n",
    "mean_reward_element = MeanRewardElement()\n",
    "episode_reward_element = EpisodeRewardElement()\n",
    "canvas_element = CanvasGrid(agent_draw, graph_dim[1], graph_dim[0], 50*graph_dim[1], 50*graph_dim[0])\n",
    "reward_chart = ChartModule([{\"Label\": \"Rewards\", \"Color\": \"Black\"}])\n",
    "\n",
    "server = ModularServer(VizModel, [canvas_element, episode_reward_element, mean_reward_element, reward_chart], \"MIPP - DDQN C51\", model_params)\n",
    "server.port = port\n",
    "port += 1\n",
    "server.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
